{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard: Visualizing Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://www.tensorflow.org/get_started/summaries_and_tensorboard\n",
    "\n",
    "The computations you'll use TensorFlow for can be complex and confusing. To make it easier to understand, debug, and optimize TensorFlow programs, TensorFlow includes a suite of visualization tools called **TensorBoard**. You can use TensorBoard to visualize your TensorFlow graph, plot quantitative metrics about the execution of your graph, and show additional data like images that pass through it.\n",
    "\n",
    "This part of the tutorial is intended to get you started with simple TensorBoard usage. There are other resources available as well! The [TensorBoard's GitHub](https://github.com/tensorflow/tensorboard) has a lot more information on TensorBoard usage, including tips & tricks, and debugging information.\n",
    "\n",
    "We'll use the code from the linear regression example and visualize what happens during training using TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we create training and testing data according to the linear model\n",
    "$y = \\text{intercept} + \\text{slope} + \\text{noise}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_noisy_data(m=0.1, b=0.3, n=100):\n",
    "    x = np.random.rand(n).astype(np.float32)\n",
    "    noise = np.random.normal(scale=0.01, size=len(x))\n",
    "    y = m * x + b + noise\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, y_train = make_noisy_data()\n",
    "x_test, y_test = make_noisy_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new ``tf.Session``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name scoping and nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typical TensorFlow graphs can have many thousands of nodes â€“ far too many to see easily all at once, or even to lay out using standard graph tools. To simplify, variable names can be scoped and the visualization uses this information to define a hierarchy on the nodes in the graph. By default, only the top of this hierarchy is shown. Here is an example that defines two placeholders under the ``input`` name scope using ``tf.name_scope``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('input'):\n",
    "    x_placeholder = tf.placeholder(shape=[None], dtype=tf.float32, name='x-input')\n",
    "    y_placeholder = tf.placeholder(shape=[None], dtype=tf.float32, name='y-input')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do the same to define the linear model in the ``model`` scope:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('model'):\n",
    "    slope = tf.Variable(0.0, name='slope')\n",
    "    intercept = tf.Variable(0.0, name='intercept')\n",
    "    y = slope * x_placeholder + intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a loss function (here, squared error) and an optimizer (here, gradient descent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.5\n",
    "\n",
    "with tf.name_scope('training'):\n",
    "    with tf.name_scope('loss'):\n",
    "        loss = tf.reduce_mean(tf.square(y - y_placeholder))\n",
    "    with tf.name_scope('optimizer'):\n",
    "        train_step = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(loss) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, our graph is complete. We're now ready to initialize variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serializing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorBoard operates by reading TensorFlow events files, which contain summary data that you can generate when running TensorFlow. Here's the general lifecycle for summary data within TensorBoard.\n",
    "\n",
    "First, create the TensorFlow graph that you'd like to collect summary data from, and decide which nodes you would like to annotate with [summary operations](https://www.tensorflow.org/api_guides/python/summary).\n",
    "\n",
    "We already created the TensorFlow graph and would like to collect summary data for the loss, slope, and intercept during training. This can be done by attaching nodes, such as ``tf.summary.scalar`` to the respective nodes in our graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Attach summaries to Tensors (for TensorBoard visualization)\n",
    "with tf.name_scope('summaries'):\n",
    "    tf.summary.scalar('slope', slope)\n",
    "    tf.summary.scalar('intercept', intercept)\n",
    "    tf.summary.scalar('loss', loss)\n",
    "\n",
    "# This op will calculate our summary data when run\n",
    "summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operations in TensorFlow don't do anything until you run them, or an op that depends on their output. And the summary nodes that we've just created are peripheral to your graph: none of the ops you are currently running depend on them. So, to generate summaries, we need to run all of these summary nodes. Managing them by hand would be tedious, so use ``tf.summary.merge_all`` to combine them into a single op that generates all the summary data.\n",
    "\n",
    "Then, you can just run the merged summary op, which will generate a ``Summary`` object with all of your summary data at a given step. Finally, to write this summary data to disk, pass the summary to a ``tf.summary.FileWriter``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is a directory we'll use to store information\n",
    "# about the graph to later visualize in TensorBoard.\n",
    "# By default, it will be created in the same directory\n",
    "# as this notebook. \n",
    "\n",
    "# Be sure to delete the contents of this directory before\n",
    "# running the script.\n",
    "LOGDIR = 'graphs'\n",
    "\n",
    "writer = tf.summary.FileWriter(join(LOGDIR, '02_linear_regression'))\n",
    "writer.add_graph(sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``FileWriter`` takes a logdir in its constructor - this logdir is quite important, it's the directory where all of the events will be written out.\n",
    "\n",
    "Now that you've modified your graph and have a ``FileWriter``, you're ready to start training! We run the merged summary op every single step during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_STEPS = 201\n",
    "\n",
    "for step in range(TRAIN_STEPS):\n",
    "    # Session will run two ops:\n",
    "    # - summary_op prepares summary data we'll write to disk in a moment\n",
    "    # - train_step will use the optimizer to adjust our variables to reduce loss\n",
    "    summary_result, _ = sess.run([summary_op, train_step], \n",
    "                                  feed_dict={x_placeholder: x_train, \n",
    "                                             y_placeholder: y_train})\n",
    "    # write the summary data to disk\n",
    "    writer.add_summary(summary_result, step)\n",
    "\n",
    "# close the writer when we're finished using it\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launching TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To start TensorBoard, run this command from a terminal:\n",
    "\n",
    "```\n",
    "tensorboard --logdir=./graphs\n",
    "```\n",
    "**Note**: you should run this from the same directory that contains this notebook\n",
    "or, provide absolute path to the 'graphs' directory.\n",
    "\n",
    "To open TensorBoard, point your browser to http://localhost:6006\n",
    "Then, click on the tabs for 'scalars', 'distributions', 'histograms', and 'graphs'\n",
    "to learn more.\n",
    "\n",
    "If you run into trouble, delete ``LOGDIR`` (to clear information from previous runs),\n",
    "then re-run this script, and restart TensorBoard.\n",
    "\n",
    "For more usage information on TensorBoard in general, see the [TensorBoard's GitHub](https://github.com/tensorflow/tensorboard)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
